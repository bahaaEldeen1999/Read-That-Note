{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import skimage.filters as fr\n",
    "import skimage.io as io\n",
    "from commonfunctions import *\n",
    "\n",
    "############################\n",
    "import joblib\n",
    "import os.path\n",
    "##########################\n",
    "import skimage as sk\n",
    "# Depending on library versions on your system, one of the following imports \n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cross_validation import train_test_splitfrom commonfunctions import *\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset = r'dataset_mixed2\\dataset_mixed'\n",
    "target_img_size = (64, 64) # fix image size because classification algorithms THAT WE WILL USE HERE expect that\n",
    "\n",
    "# We are going to fix the random seed to make our experiments reproducible \n",
    "# since some algorithms use pseudorandom generators\n",
    "random_seed = 42  \n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img):\n",
    "    \n",
    "    \"\"\"\n",
    "    TODO\n",
    "    You won't implement anything in this function. You just need to understand it \n",
    "    and understand its parameters (i.e win_size, cell_size, ... etc)\n",
    "    \"\"\"\n",
    " #   thr = fr.threshold_otsu(img)\n",
    " #   img = np.where(img > thr, 1, 0)\n",
    "    img = cv2.resize(img, target_img_size)\n",
    "    win_size = (64, 64)\n",
    "    cell_size = (8, 8)\n",
    "    block_size_in_cells = (4, 4)\n",
    "    \n",
    "    block_size = (block_size_in_cells[1] * cell_size[1], block_size_in_cells[0] * cell_size[0])\n",
    "    block_stride = (cell_size[1], cell_size[0])\n",
    "    nbins =4 # Number of orientation bins\n",
    "    hog = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, nbins)\n",
    "    h = hog.compute(img)\n",
    "    h = h.flatten()\n",
    "    \n",
    "    return h.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    features = []\n",
    "    labels = []\n",
    "    img_filenames = os.listdir(path_to_dataset)\n",
    "\n",
    "    for i, fn in enumerate(img_filenames):\n",
    "        if fn.split('.')[-1] != 'jpg' and fn.split('.')[-1] != 'bmp' and fn.split('.')[-1] != 'png' :\n",
    "            continue\n",
    "\n",
    "        label = fn.split('-')[0]\n",
    "      #  print(label)\n",
    "        labels.append(label)\n",
    "\n",
    "        path = os.path.join(path_to_dataset, fn)\n",
    "        img = cv2.imread(path)\n",
    "        features.append(extract_features(img))\n",
    "        # show an update every 1,000 images\n",
    "        if i > 0 and i % 1000 == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i, len(img_filenames)))\n",
    " \n",
    "        \n",
    "    return features, labels        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'SVM': svm.LinearSVC(random_state=random_seed)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will test all our classifiers on a specific feature set\n",
    "def run_experiment():\n",
    "    \n",
    "    # Load dataset with extracted features\n",
    "    print('Loading dataset. This will take time ...')\n",
    "    features, labels = load_dataset()\n",
    "#    print(features)\n",
    "#    print(labels)\n",
    "    print('Finished loading dataset.')\n",
    "    \n",
    "    # Since we don't want to know the performance of our classifier on images it has seen before\n",
    "    # we are going to withhold some images that we will test the classifier on after training \n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "        features, labels, test_size=0.2, random_state=random_seed)\n",
    "    \n",
    "    for model_name, model in classifiers.items():\n",
    "        print('############## Training', model_name, \"##############\")\n",
    "        # Train the model only on the training features\n",
    "        model.fit(train_features, train_labels)\n",
    "        # save the model to disk\n",
    "        filename = 'finalized_model.sav'\n",
    "        joblib.dump(model, filename)\n",
    "        \n",
    "        # Test the model on images it hasn't seen before\n",
    "        accuracy = model.score(test_features, test_labels)\n",
    "        print(model_name, 'accuracy:', accuracy*100, '%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset. This will take time ...\n",
      "[INFO] processed 1000/9686\n",
      "[INFO] processed 2000/9686\n",
      "[INFO] processed 3000/9686\n",
      "[INFO] processed 4000/9686\n",
      "[INFO] processed 5000/9686\n",
      "[INFO] processed 6000/9686\n",
      "[INFO] processed 7000/9686\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('finalized_model.sav'):\n",
    "    ##### the model already exit####\n",
    "    print(\"model already exit\")\n",
    "else:\n",
    "    ### not exit so train ###\n",
    "    run_experiment()\n",
    "    \n",
    "##########################################    \n",
    "\n",
    " # load the model from disk\n",
    "loaded_model = joblib.load('finalized_model.sav')\n",
    "    # Example\n",
    "testpathes=['20-1.png','##-1.jpg','#-1 (1).jpg','#-1 (2).jpg','&-0.jpg','[-0.jpg',']-1 (1).jpg','_8-0.jpg','-1.jpg','o.jpg','37389233_396700974895750_7474734536425302407_n.jpg' ,'13738923_396700974895750_7474734536425302407_n.jpg','5-1 (1).png']\n",
    "for path in testpathes:\n",
    "    img = cv2.imread( path )\n",
    "    show_images([img])\n",
    "    features = extract_features(img)\n",
    "    print(loaded_model.predict([features]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_chord_or_beam(img, staff_space):\n",
    "    '''\n",
    "        **img is assumed to be binarized\n",
    "        returns:\n",
    "            0 --> chord\n",
    "            1 --> beam\n",
    "           -1 --> neither\n",
    "    '''\n",
    "\n",
    "    se = sk.morphology.disk(staff_space//2)\n",
    "    img = sk.morphology.binary_opening(img, se)\n",
    "    img = sk.morphology.binary_erosion(img, se)\n",
    "    img = sk.morphology.binary_erosion(img)\n",
    "    se = sk.morphology.disk(staff_space//4)\n",
    "    img = sk.morphology.binary_dilation(img, se)\n",
    "    bounding_boxes = sk.measure.find_contours(img, 0.8)\n",
    "\n",
    "    if len(bounding_boxes) < 2:\n",
    "        return -1\n",
    "\n",
    "    newImg = img.copy()\n",
    "    centers, cnt = [], 0\n",
    "\n",
    "    for box in bounding_boxes:\n",
    "        [Xmin, Xmax, Ymin, Ymax] = [np.min(box[:, 1]), np.max(\n",
    "            box[:, 1]), np.min(box[:, 0]), np.max(box[:, 0])]\n",
    "        rr, cc = sk.draw.rectangle(\n",
    "            start=(Ymin, Xmin), end=(Ymax, Xmax), shape=newImg.shape)\n",
    "        rr, cc = rr.astype(int), cc.astype(int)\n",
    "        newImg[rr, cc] = 1\n",
    "        centers.append([Ymin+Ymin//2, Xmin+Xmin//2])\n",
    "\n",
    "    for i in range(1, len(centers)):\n",
    "        if abs(centers[i][1] - centers[i-1][1]) > 70:\n",
    "            cnt += 1\n",
    "\n",
    "    if cnt == len(centers)-1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = io.imread(\"chords_2.png\", as_gray=True)\n",
    "print(check_chord_or_beam(img1, 17))\n",
    "img2 = io.imread(\"beaming_4.png\", as_gray=True)\n",
    "print(check_chord_or_beam(img2,17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classfiyimg(img,staff_space):\n",
    "    out=check_chord_or_beam(img, staff_space)\n",
    "    if(out==-1):\n",
    "        features = extract_features(img)\n",
    "        print(loaded_model.predict([features]))\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
